<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta content="IE=5.0000" http-equiv="X-UA-Compatible">
  <meta name="description" content="Chong-Yu Zhang&#39;s home page">
  <meta name="keywords" content="***,Chong-Yu Zhang" />
  
  <link href="./imgs/tlzdoc.css" rel="stylesheet" type="text/css">
  <title>Chong-Yu Zhang's Homepage--***的个人主页</title>
  <meta name="GENERATOR" content="MSHTML 11.00.10570.1001">
</head>


<body>
  <div id="layout-content" style="margin-top: 25px;">
  <table>
    <tbody>
    <tr>
      <td>
        &nbsp;&nbsp;&nbsp;<img width="180" src="../images/miaomiao.png" border="100">
      </td>	
      <td width="670">
        <div id="toptitle">
        <h1>&nbsp;&nbsp;&nbsp; Chong-Yu Zhang &nbsp; ***<a name="top"></a></h1>
		</div>
         &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Graduate Student <br> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Shandong University MIMA Lab<br>
        <p>
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Email: zhangchongyu22[at]gmail[dot]com
        <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
	&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/zcyueternal" target="_blank">[Github]</a>
	&nbsp;&nbsp;<a href="https://scholar.google.com.hk/citations?user=OsbUzCMAAAAJ&hl=en" target="_blank">[Scholar]</a>	
  <!--      &nbsp;&nbsp;<a href="#" target="_blank">[Ph.D. Thesis, in Chinese]</a>		-->
        <br><br></p>
		&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  
    <font color="red">Academic life is not all, but it can be a part.</font>
    <br><br>
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    <font color="red">Last modified date: 02/28/2024</font>
      </td>
    </tr>
    <tr></tr></tbody>
  </table>
  <div id="layout-content" style="margin-top: 25px;">


<h4>[<a style=" color:#9D849A;" href="#biography">Biography</a>] [<a style=" color:#9D849A;" href="#news">Latest News</a>] [<a style=" color:#9D849A;" href="#publications">Publications</a>] <!--[<a style=" color:#9D849A;" href="#patents">Patents</a>] -->
[<a style=" color:#9D849A;" href="#services">Academic Services & Leadership</a>] [<a style=" color:#9D849A;" href="#awards">Major Awards</a>] </h4>


<h2>Biography<a name="biography"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>

<div>  
<!-- <p style="text-indent:2em;"> I am a senior researcher at Tencent, where I work on computer vision and information retrieval. 
      I finished the M.S.-Ph.D. study and obtained my Ph.D. degree from Xiamen University in 2022, advised by <a href="https://mac.xmu.edu.cn/rrji_en/" target="_blank">Prof. Rongrong Ji</a>.
	  Earlier, I received the B.S. degree from Fuzhou University in 2016.
  </p>
  <p style="text-indent:2em;">My recent research interests are to develop efficient vision models, image/text retrieval, as well as vision/language pretraining.</p> -->

  I am currently a Graduate student at  <a href="https://mima.sdu.edu.cn">MIMA</a> Lab, Shandong University, advised by Associate Professor <a href="https://faculty.sdu.edu.cn/luoxin/zh_CN/index.htm">Xin Luo</a>, co-advised by Professor <a href="https://faculty.sdu.edu.cn/xuxinshun/zh_CN/index.htm">Xin-Shun Xu</a>. Before that, I received my Bachelor’s degree in School of Information Science and Engineering, University of Jinan, Jinan, Shandong, China, in 2022, supervised by Associate Professor <a href ="http://2021.yzadm.ujn.edu.cn/Page/Dsxx/ssds_data/ssds_id/a8ba7dfc-7b89-18f8-af5c-5c4705349712/status/1.html">Peng Wu</a>, <a href ="http://2021.yzadm.ujn.edu.cn/Page/Dsxx/ssds_data/ssds_id/a8ba7dfc-7b89-18f8-af5c-5c4705349712/status/1.html">Jie Su</a>, and Professor <a href ="https://ujnview.github.io/">Xiuyang Zhao</a>.

  My current research topics are Information Retrieval and Machine Learning. I mainly focus on hashing retrieval, especially online hashing and multi-modal retrieval. Besides, I am also open and willing to explore other vision tasks, e.g., incremental learning, prompt learning, vision-language pretraining, and federated learning. <b>If you are interested in my topics, please do not hesitate to reach out.</b>

<ul>  
  <!-- <li> 07/2022 -- Now: Senior Researcher, <a href="https://open.youtu.qq.com/#/open"  target="_blank">Tencent Youtu Lab</a>, Shanghai, China </li>
  <li> 09/2019 -- 06/2022: Research Intern, <a href="https://www.pcl.ac.cn/" target="_blank">Peng Cheng Lab</a>, Shenzhen, China </li>
  <li> 09/2018 -- 06/2022: Ph.D. in xxxxxx, <a href="http://mima.sdu.edu.cn/"  target="_blank">MIMA</a> Lab, Shandong University, Jinan, China</li> -->
  <li> 09/2022 -- Now: M.S. Candidates in Artificial Intelligence, <a href="http://mima.sdu.edu.cn/"  target="_blank">MIMA</a> Lab, Shandong University, Jinan, China</li>
  <div style="font-size: small;">
      Hashing retrieval (Online Hashing)
  </div>
  <li> 09/2018 -- 06/2022: B.S. in Network Engineering, University of Jinan, Jinan, China </li>
</ul> 
</div>


<h2>Latest News<a name="news"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
  <li>[07/2023] One paper is accepted by ACM MM 2023. </li>
  <!-- <li> 07/2022: Five papers (including one oral paper) accepted by ECCV 2022</li>
  <li> 07/2022: Senior Researcher, Tencent, Shanghai, China</li>
  <li> 06/2022: Outstanding Ph.D. Graduate Student, Xiamen University</li> -->
</ul>


<h2>Publications<a name="publications"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<h3>Journal/Trans</h3>
<table class="pub_table">
  <tbody>
  <tr>
    <td class="pub_td1">001<img src="../images/miaomiao.png" class="papericon"></td>
    <td class="pub_td2"><font color="goldenrod">Chong-Yu Zhang</font>, Xin Luo<sup>✉</sup>, Yu-Wei Zhan, Yongxin Wang, Zhen-Duo Chen, Peng-Fei Zhang, Xin-Shun Xu
      <br><b>Gleaning Wisdom from the Past: Towards Label Incremental Learning for Online Hashing with a Plug-and-Play Framework</b>
      <br><em>submitted to IEEE Transactions on Image Processing, 2024</em>
      
      <br>
      <!-- [<a href="https://ieeexplore.ieee.org/document/xxxxxxx" target="_blank">pdf</a>]                    
      [<a href="#" target="_blank">arXiv</a>]
      [<a href="https://github.com/zcyueternal/xxx" target="_blank">code</a>] -->
    </td>
  </tr>

  <tr>
    <td class="pub_td1">002<img src="../images/miaomiao.png" class="papericon"></td>
    <td class="pub_td2">Junjie Peng<sup>*</sup>, <font color="goldenrod">Chong-Yu Zhang<sup>*</sup></font>, Xin Luo<sup>✉</sup>, Yu-Wei Zhan, Peng-Fei Zhang, Zhen-Duo Chen, Xin-Shun Xu
      <br><b>Hierarchical Label Incremental Online Hashing for Cross-modal Retrieval</b>
      <br><em>submitted to Pattern Recognition (PR), 2024</em>
      <br>
      <!-- [<a href="https://ieeexplore.ieee.org/document/xxxxxxx" target="_blank">pdf</a>]                    
      [<a href="#" target="_blank">arXiv</a>]
      [<a href="https://github.com/zcyueternal/xxx" target="_blank">code</a>] -->
    </td>
  </tr>

  <tr>
    <td class="pub_td1">003<img src="../images/miaomiao.png" class="papericon"></td>
    <td class="pub_td2">Na Wang, <font color="goldenrod">Chong-Yu Zhang</font>, Xin Luo<sup>✉</sup>, Yu-Wei Zhan, Zhen-Duo Chen, Peng-Fei Zhang, Xin-Shun Xu
      <br><b>Dynamic Clustering-Driven Weakly-Supervised Online Hashing with Enhanced Similarity</b>
      <br><em>submitted to Pattern Recognition (PR), 2024</em>
      <br>
      <!-- [<a href="https://ieeexplore.ieee.org/document/xxxxxxx" target="_blank">pdf</a>]                    
      [<a href="#" target="_blank">arXiv</a>]
      [<a href="https://github.com/zcyueternal/xxx" target="_blank">code</a>] -->
    </td>
  </tr>

  <tr>
    <td class="pub_td1">004<img src="../images/miaomiao.png" class="papericon"></td>
    <td class="pub_td2">Tai Zheng, Zhen-Duo Chen<sup>✉</sup>, Zi-Chao Zhang, Zhen-Xiang Ma, Li-Jun Zhao, <font color="goldenrod">Chong-Yu Zhang</font>, Xin Luo, Xin-Shun Xu
      <br><b>DGPrompt: Dual-Guidance Prompts Generation for Vision-Language Models</b>
      <br><em>submitted to XXX (XXX), 2024</em>
      <br>
      <!-- [<a href="https://ieeexplore.ieee.org/document/xxxxxxx" target="_blank">pdf</a>]                    
      [<a href="#" target="_blank">arXiv</a>]
      [<a href="https://github.com/zcyueternal/xxx" target="_blank">code</a>] -->
    </td>
  </tr>


  

  <!-- <tr>
    <td class="pub_td1">008<img src="./imgs/dmad.jpg" class="papericon"></td>
    <td class="pub_td2"><font color="goldenrod">Chong-Yu Zhang</font>, Xin Luo<sup>✉</sup>, Yu-Wei Zhan, Peng-Fei Zhang, Zhen-Duo Chen, Xin-Shun Xu
      <br><b>xxx</b>
      <br>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 2024
      <br>
      [<a href="https://ieeexplore.ieee.org/document/xxxxxxx" target="_blank">pdf</a>]                    
      [<a href="#" target="_blank">arXiv</a>]
      [<a href="https://github.com/zcyueternal/xxx" target="_blank">code</a>]
    </td>
  </tr> -->

  <!-- <tr>
    <td class="pub_td1">001<img src="./imgs/splh.jpg" class="papericon"></td>
    <td class="pub_td2"><font color="goldenrod">Chong-Yu Zhang</font>, Xin Luo<sup>✉</sup>, Yu-Wei Zhan, Peng-Fei Zhang, Zhen-Duo Chen, Xin-Shun Xu
      <br><b>xxx Hashing for Online cross modal Retrieval</b>
      <br>Pattern Recognition (PR), 2024
      <br>
      [<a href="#" target="_blank">pdf</a>]                    
      [<a href="https://github.com/zcyueternal/xxxx" target="_blank">code</a>]
    </td>
  </tr> -->

  </tbody>
</table>

<h3>Conference</h3>
<table class="pub_table">
  <tbody>

  <tr>
    <td class="pub_td1">001<img src="../images/miaomiao.png" class="papericon"></td>
    <td class="pub_td2"><font color="goldenrod">Chong-Yu Zhang</font>, Xin Luo<sup>✉</sup>, Yu-Wei Zhan, Peng-Fei Zhang, Zhen-Duo Chen, Yongxin Wang, Xun Yang, Xin-Shun Xu
      <br><b>Self-Distillation Dual-Memory Online Hashing with Hash Centers for Streaming Data Retrieval</b>
      <br>ACM International Conference on Multimedia (ACM MM), 2023
      <br>
      [<a href="https://doi.org/10.1145/3581783.3612119" target="_blank">pdf</a>]
      [<a href="https://github.com/ZCyueternal/SDOH-HC" target="_blank">code</a>]
	  
    </td>
  </tr>
  
  
  
  <!-- <tr>
    <td class="pub_td1">003<img src="./imgs/ljl_framework.jpg" class="papericon"></td>
    <td class="pub_td2">Na Wang, Yu-Wei Zhan, <font color="goldenrod">Chong-Yu Zhang</font>, Xin Luo<sup>✉</sup>, Zhen-Duo Chen, Xin-Shun Xu
      <br><b>online cross modal hashing</b>
      <br>IEEE Transactions on Neural Networks and Learning Systems (TNNLS), 202x
      <br>
      [<a href="https://ieeexplore.ieee.org/document/xxxxxxx" target="_blank">pdf</a>]                    
      [<a href="https://arxiv.org/abs/23xx.xxxxx" target="_blank">arXiv</a>]
      [<a href="https://github.com/carrieliu/xxx" target="_blank">code</a>]
    </td>
  </tr> -->

  <!-- <tr>
    <td class="pub_td1">002<img src="./imgs/wn_framework.png" class="papericon"></td>
    <td class="pub_td2">xxx<sup>*</sup>, <font color="goldenrod">Chong-Yu Zhang</font><sup>*</sup>, Xin Luo<sup>✉</sup>, Zhen-Duo Chen, Xin-Shun Xu
      <br><b>xxxxx</b>
      <br>To be defined (), 2024
      <br>
      [<a href="#" target="_blank">pdf</a>]                    
      [<a href="#" target="_blank">code</a>] 
	  (<sup>*</sup> Equal Contribution)
    </td>
  </tr> -->

  </tbody>
</table>

<h3>Preprint</h3>
<table class="pub_table">
  <tbody>
  
    <tr>
      <td class="pub_td1">001<img src="../images/miaomiao.png" class="papericon"></td>
      <td class="pub_td2">Jia-Le Liu, Yu-Wei Zhan, <font color="goldenrod">Chong-Yu Zhang</font>, Xin Luo<sup>✉</sup>, Zhen-Duo Chen, Yinwei Wei, Xin-Shun Xu
        <br><b>Federated Class-Incremental Learning with Prompting</b>
        <br>arxiv, 2023
        <br>
        [<a href="https://arxiv.org/pdf/2310.08948.pdf" target="_blank">arxiv</a>]
        <!-- [<a href="https://github.com/carrieliu/xxx" target="_blank">code</a>] -->
      </td>
    </tr>

  <!-- <tr>
    <td class="pub_td1">001<img src="./imgs/arxivzcyu.png" class="papericon"></td>
    <td class="pub_td2"><font color="goldenrod">Chong-Yu Zhang</font>, Xin Luo<sup>✉</sup>, Fang-Yi Liang, Zhen-Duo Chen, Xin-Shun Xu
      <br><b>federated few-shot class-incremental learning</b>
      <br>arXiv preprint arXiv:23xx.xxxxx, 2023
      <br>
	  [<a href="https://arxiv.org/abs/23xx.xxxxx" target="_blank">arXiv</a>]
	  [<a href="https://github.com/zcyueternal/xxx-xxxxxx" target="_blank">code</a>]
    </td>
  </tr>   -->
   
  </tbody>
</table>


<h2>Patents<a name="patents"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<table class="pub_table">
 <tbody>
  <tr></tr>
  <tr>
    <td class="pub_td1">001</td> 
   <td class="pub_td2"> 罗昕, <font color="goldenrod">张崇宇</font>, 陈振铎, 许信顺
     <br><b>一种缓解灾难性遗忘的在线哈希检索方法及系统</b>
   </td>
 </tr>


  <tr>
     <td class="pub_td1">002</td> 
    <td class="pub_td2"> 罗昕, <font color="goldenrod">张崇宇</font>, 许信顺
      <br><b>基于流形排序学习的在线无监督跨模态检索方法及系统</b>
    </td>
  </tr>	

  <!-- <tr>
    <td class="pub_td1">003</td> 
   <td class="pub_td2"> 罗昕, <font color="goldenrod">张崇宇</font>, 许信顺
     <br><b>XXXX</b>
   </td>
 </tr>	 -->

  </tbody>
</table>
  


<h2>Academic Services & Leadership<a name="services"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
  <li>Conference Reviewer: MM(2024), ICME(2023), PAKDD(2023), ECML-PKDD(2023), etc.</li>
  <li>Datawhale Open-source Organization Propaganda Ambassador</li>
  <!-- <li>Journal Reviewer: </li> -->
</ul>
<!-- <ul>
    <li>Conference Reviewer: </li>
	IEEE/CVF Computer Vision and Pattern Recognition (CVPR), 2021--2023. </br>
	IEEE/CVF International Conference on Computer Vision (ICCV), 2021. <br/>
	European Conference on Computer Vision (ECCV), 2022. <br/>
	International Conference on Machine Learning (ICML), 2021--2023. <br/>
	Conference on Neural Information Processing Systems (NeurIPS), 2022. <br/>
	Association for the Advancement of Artificial Intelligence (AAAI), 2021--2023. <br/>
	
    <li>Journal Reviewer: </li>
	IEEE Transactions on Pattern Analysis and Machine Intelligence (IEEE TPAMI). <br/>
	International Journal of Computer Vision (IJCV). <br/>
	Journal of Machine Learning Research (JMLR). <br/>
	IEEE Transactions on Image Processing (IEEE TIP). <br/>
	IEEE Transactions on Neural Networks and Learning Systems (IEEE TNNLS). <br/>
	IEEE Transactions on Multimedia (IEEE TMM). <br/>
	IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT). <br/>
	IEEE Transactions on Network Science and Engineering (IEEE TNSE). <br/>
	Pattern Recognition (PR). <br/>
	Neurocomputing (NEUCOM). <br/>
	Neural Networks (NEUNET). <br/>
	Neural Computing and Applications (NCAA). <br/>
	Applied Intelligence (APIN). <br/>
	Artificial Intelligence Review. <br/>
	Science China Information Sciences (SCIS). <br/>
    Journal of Visual Communication and Image Representation (JVCI). <br/>
</ul> -->

<h2>Major Awards<a name="awards"></a>&nbsp;&nbsp;&nbsp;<a style=" color:#9D849A; font-size:15px;" href="#top">[back top]</a></h2>
<ul>
  <li>Major Awards in Shandong University, 2022, 2023.</li>
  <li>Major Awards in University of Jinan, 2019, 2020, 2021 <b>(three times).</b></li>
  
</ul>
<!-- <ul>
    <li>Outstanding Contributions, IEEE Standard 2941<sup style="vertical-align:top;"><font style="font-size:1px">TM</font></sup> - 2022, 2022</li>
    <li>Outstanding Ph.D. Graduate Student, Xiamen University, 2022</li>
	<li>Outstanding Merit Student, Xiamen University, 2021</li>
    <li>National Scholarship (Ph.D.), China, 2021</li>
    <li>National Scholarship (Ph.D.), China, 2020</li>
</ul> -->


</div>
</div>
</body>
</html>
